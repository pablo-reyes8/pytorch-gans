# MNIST - Generative Adversarial Network

![Repo size](https://img.shields.io/github/repo-size/pablo-reyes8/mnist-gan)
![Last commit](https://img.shields.io/github/last-commit/pablo-reyes8/mnist-gan)
![Open issues](https://img.shields.io/github/issues/pablo-reyes8/mnist-gan)
![Contributors](https://img.shields.io/github/contributors/pablo-reyes8/mnist-gan)
![Forks](https://img.shields.io/github/forks/pablo-reyes8/mnist-gan?style=social)
![Stars](https://img.shields.io/github/stars/pablo-reyes8/mnist-gan?style=social)



An implementation of a **Generative Adversarial Network (GAN)** in PyTorch, trained on the MNIST dataset to generate realistic handwritten digits.  
This repository demonstrates the core principles of adversarial training through a clean and well-structured codebase, making it both a practical learning resource and a solid foundation for extending towards more advanced GAN architectures.


---

## ğŸ“‚ Project Structure

```plaintext
â”œâ”€â”€ samples/ # Generated images during training
â”œâ”€â”€ gan-model/ # Core GAN implementation
â”‚ â”œâ”€â”€ gan_full.ipynb # End-to-end notebook: training + visualization
â”‚ â”œâ”€â”€ load_data.py # Data loading utilities (MNIST, transforms, DataLoader)
â”‚ â”œâ”€â”€ model.py # Generator and Discriminator model definitions
â”‚ â”œâ”€â”€ train_model.ipynb # Training workflow (notebook version)
â”‚ â”œâ”€â”€ training.py # Training loop implementation with logging and sampling
```

---

## âš™ï¸ Main Components

- **`model.py`**  
  Defines the **Generator** and **Discriminator** networks using `torch.nn.Module`.  
  - Generator: maps latent vectors (z âˆˆ â„^100) to 32Ã—32 grayscale images.  
  - Discriminator: classifies images as real (from MNIST) or fake (from the generator).  

- **`training.py`**  
  Contains the training loop for the GAN. Handles forward/backward passes, optimizer steps, and periodic image sampling for monitoring progress.  

- **`load_data.py`**  
  Loads and preprocesses the MNIST dataset, applying normalization and batching for training.  

- **`gan_full.ipynb`**  
  Jupyter Notebook that ties together the data, models, and training loop in one interactive script. Ideal for experimenting and visualizing results.  

- **`train_model.ipynb`**  
  Focused notebook for running the training pipeline with logging of loss values and generated samples.  

- **`samples/`**  
  Stores generated images at different epochs, allowing visualization of the GANâ€™s learning progress.  

---

## ğŸš€ Results

After training for ~20 epochs, the generator produces recognizable handwritten digits. With more epochs and training tricks (e.g., label smoothing, improved architectures), the results can be significantly improved.  

<p align="center">
  <img src="samples/epoch_0020.png" alt="Generated digits at epoch 20" width="300"/>
</p>


---

## Requirements

```bash
pip install torch torchvision matplotlib
```
  
---

## ğŸ“š References

- Ian Goodfellow et al. (2014). *Generative Adversarial Nets*. NeurIPS.  
- Alec Radford, Luke Metz, Soumith Chintala (2015). *Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)*.  
- PyTorch Documentation: [https://pytorch.org/docs/stable/](https://pytorch.org/docs/stable/)

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## âœ¨ Future Work

- Experiment with **Wasserstein GAN (WGAN)** and gradient penalty.  
- Extend to **color datasets** like CIFAR-10.  
- Add logging and visualization with **TensorBoard**.  
- Explore **conditional GANs (cGANs)** for class-conditioned digit generation.

