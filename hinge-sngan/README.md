# Hinge-SNGAN â€“ CIFRAR 10 Clases 

![Repo size](https://img.shields.io/github/repo-size/pablo-reyes8/pytorch-gans)
![Last commit](https://img.shields.io/github/last-commit/pablo-reyes8/pytorch-gans)
![Open issues](https://img.shields.io/github/issues/pablo-reyes8/pytorch-gans)
![Contributors](https://img.shields.io/github/contributors/pablo-reyes8/pytorch-gans)
![Forks](https://img.shields.io/github/forks/pablo-reyes8/pytorch-gans?style=social)
![Stars](https://img.shields.io/github/stars/pablo-reyes8/pytorch-gans?style=social)

An implementation of a **Spectral Normalization GAN (SNGAN)** with **Hinge Loss**, **R1 regularization**, **Exponential Moving Average (EMA)** and **DiffAugment**, trained on the **CIfar10** to generate 64Ã—64 color images.

This project extends the baseline GAN setup with modern stabilization techniques, making it more robust on small datasets.

---

## ğŸ“‚ Project Structure

```plaintext
hinge-sngan/
â”œâ”€â”€ samples_first_training/     # Generated samples from the first run
â”‚   â”œâ”€â”€ epoch_0005.png
â”‚   â”œâ”€â”€ epoch_0020.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ samples_second_training/    # Generated samples from a second run
â”‚   â”œâ”€â”€ epoch_0010.png
â”‚   â”œâ”€â”€ epoch_0025.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                        # Core implementation
â”‚   â”œâ”€â”€ load_data.py            # Cifrar dataloader & preprocessing
â”‚   â”œâ”€â”€ loss_hinge.py           # Hinge + R1 losses
â”‚   â”œâ”€â”€ model.py                # Generator & Discriminator (with SN)
â”‚   â”œâ”€â”€ train_loop.py           # Training loop with R1, EMA, DiffAug
â”‚   â””â”€â”€ training_utils.py       # Utility functions (sampling, init, etc.)
â””â”€â”€ training/                   # Notebooks for experimentation
    â”œâ”€â”€ hinge_sngan_first_training.ipynb
    â”œâ”€â”€ hinge_sngan_second_training.ipynb
    â””â”€â”€ hinge_sngan_full.ipynb
```

---

---

## âš™ï¸ Main Components

- **Generator & Discriminator**

  - Generator: maps latent vectors (_z_ âˆˆ â„^100) into 64Ã—64Ã—3 RGB images.
  - Discriminator: convolutional classifier with **Spectral Normalization** for stable gradients.

- **Loss Functions**  
  Implements **hinge loss** for adversarial training and **R1 gradient penalty** for discriminator regularization.

- **Training Loop**  
  Includes advanced features such as:

  - Multiple discriminator updates per batch.
  - Warm-up phase with extra generator steps.
  - **Exponential Moving Average (EMA)** of generator weights.
  - **Differentiable Augmentation (DiffAugment)** for small datasets.

- **Samples**  
  Generated outputs from multiple training runs are stored to visualize progression over epochs.

- **Notebooks**  
  End-to-end notebooks for training, evaluation, and visualization.

---

## ğŸš€ Results

After ~50â€“80 epochs, the generator begins producing recognizable dog/cat-like images at 64Ã—64 resolution.  
EMA and DiffAugment significantly improve stability and sample quality compared to plain hinge-SNGAN.

<p align="center">
  <img src="samples_final/Samples Final.png" alt="Oxford Pets Hinge-SNGAN sample" width="280"/>
</p>

---

## ğŸ“š References

- Miyato et al. (2018). [_Spectral Normalization for Generative Adversarial Networks_](https://arxiv.org/abs/1802.05957).
- Mescheder et al. (2018). [_Which Training Methods for GANs do actually Converge?_](https://arxiv.org/abs/1801.04406).
- Zhao et al. (2020). [_Differentiable Augmentation for Data-Efficient GAN Training_](https://arxiv.org/abs/2006.10738).
- Karras et al. (2019). [_A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN)_](https://arxiv.org/abs/1812.04948).

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## âœ¨ Future Work

- Extend training to larger datasets like **CelebA-HQ**.
- Experiment with **larger architectures (BigGAN-lite)**.
- Evaluate image quality with **FID/KID metrics**.




